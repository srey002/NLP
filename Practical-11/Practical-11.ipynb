{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "widespread-fitting",
   "metadata": {},
   "source": [
    "# Prac11 Implement HMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "handed-spider",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pressing-momentum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('The', 'AT'), ('Fulton', 'NP-TL'), ('County', 'NN-TL'), ('Grand', 'JJ-TL'), ('Jury', 'NN-TL'), ('said', 'VBD'), ('Friday', 'NR'), ('an', 'AT'), ('investigation', 'NN'), ('of', 'IN'), (\"Atlanta's\", 'NP$'), ('recent', 'JJ'), ('primary', 'NN'), ('election', 'NN'), ('produced', 'VBD'), ('``', '``'), ('no', 'AT'), ('evidence', 'NN'), (\"''\", \"''\"), ('that', 'CS'), ('any', 'DTI'), ('irregularities', 'NNS'), ('took', 'VBD'), ('place', 'NN'), ('.', '.')], [('The', 'AT'), ('jury', 'NN'), ('further', 'RBR'), ('said', 'VBD'), ('in', 'IN'), ('term-end', 'NN'), ('presentments', 'NNS'), ('that', 'CS'), ('the', 'AT'), ('City', 'NN-TL'), ('Executive', 'JJ-TL'), ('Committee', 'NN-TL'), (',', ','), ('which', 'WDT'), ('had', 'HVD'), ('over-all', 'JJ'), ('charge', 'NN'), ('of', 'IN'), ('the', 'AT'), ('election', 'NN'), (',', ','), ('``', '``'), ('deserves', 'VBZ'), ('the', 'AT'), ('praise', 'NN'), ('and', 'CC'), ('thanks', 'NNS'), ('of', 'IN'), ('the', 'AT'), ('City', 'NN-TL'), ('of', 'IN-TL'), ('Atlanta', 'NP-TL'), (\"''\", \"''\"), ('for', 'IN'), ('the', 'AT'), ('manner', 'NN'), ('in', 'IN'), ('which', 'WDT'), ('the', 'AT'), ('election', 'NN'), ('was', 'BEDZ'), ('conducted', 'VBN'), ('.', '.')], ...]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brown.tagged_sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "polish-tribune",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of all the unique tags from the corpus\n",
    "\n",
    "brown_word_tags=[]\n",
    "\n",
    "#Manually adding the start and the end tag\n",
    "for brown_sent in brown.tagged_sents():\n",
    "    brown_word_tags.append(('START','START'))\n",
    "    \n",
    "    for words,tag in brown_sent:\n",
    "        brown_word_tags.extend([(tag[:2],words)])\n",
    "        \n",
    "    brown_word_tags.append(('END','END'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "steady-borough",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the continuous frequency distribution for the words which are tagged\n",
    "cfd_tag_words=nltk.ConditionalFreqDist(brown_word_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "banner-expense",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the conditional probability distribution\n",
    "cpd_tag_words=nltk.ConditionalProbDist(cfd_tag_words,nltk.MLEProbDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "consecutive-referral",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of an adjective (JJ) being 'smart' is 0.00027780092785509904\n",
      "The probability of a verb (VB) being 'try' is 0.0010790559555256297\n"
     ]
    }
   ],
   "source": [
    "print(\"The probability of an adjective (JJ) being 'smart' is\", cpd_tag_words[\"JJ\"].prob(\"smart\"))\n",
    "print(\"The probability of a verb (VB) being 'try' is\", cpd_tag_words[\"VB\"].prob(\"try\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "surrounded-asset",
   "metadata": {},
   "outputs": [],
   "source": [
    "brown_tags=[]\n",
    "for tag, words in brown_word_tags:\n",
    "    brown_tags.append(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "stainless-identification",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make conditional frequency distribution: count(t{i-1} ti)\n",
    "cfd_tags=nltk.ConditionalFreqDist(nltk.bigrams(brown_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "specified-climb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make conditional probability distribution, using maximum likelihood estimate: P(ti | t{i-1})\n",
    "cpd_tags=nltk.ConditionalProbDist(cfd_tags,nltk.MLEProbDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "authorized-transport",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The probability of DT occuring after NN is :  0.0018349509874933604\n",
      "The probability of VB occuring after NN is :  0.0646359290427087\n"
     ]
    }
   ],
   "source": [
    "print('The probability of DT occuring after NN is : ', cpd_tags[\"NN\"].prob(\"DT\"))\n",
    "print('The probability of VB occuring after NN is : ', cpd_tags[\"NN\"].prob(\"VB\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minor-nancy",
   "metadata": {},
   "source": [
    "# Implementation of Viterbi algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "right-smooth",
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct_brown_tags=set(brown_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "contrary-present",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_sentences=[\"I\",\"love\",\"spicy\",\"food\"]\n",
    "len_sample_sentence=len(sample_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "varied-arkansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "viterbi_tags={}\n",
    "viterbi_backpointer={}\n",
    "\n",
    "for tag in distinct_brown_tags:\n",
    "    if tag==\"START\":\n",
    "        continue\n",
    "    viterbi_tags[tag]=cpd_tags[\"START\"].prob(tag)*cpd_tag_words[tag].prob(sample_sentences[0])\n",
    "    viterbi_backpointer[tag]=\"START\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "legendary-planner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each step i in 1 .. sentlen,\n",
    "# store a dictionary\n",
    "# that maps each tag X\n",
    "# to the probability of the best tag sequence of length i that ends in X\n",
    "\n",
    "\n",
    "\n",
    "viterbi_main=[]\n",
    "backpointer_main=[]\n",
    "\n",
    "viterbi_main.append(viterbi_tags)\n",
    "backpointer_main.append(viterbi_backpointer)\n",
    "\n",
    "current_best=max(viterbi_tags.keys(),key=lambda tag: viterbi_tags[tag])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "verbal-oliver",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 'I' current best two-tag sequence: START PP\n"
     ]
    }
   ],
   "source": [
    "print(\"Word\", \"'\" + sample_sentences[0] + \"'\", \"current best two-tag sequence:\", viterbi_backpointer[current_best], current_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "analyzed-angle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 'love' current best two-tag sequence: PP NN\n",
      "Word 'spicy' current best two-tag sequence: VB JJ\n",
      "Word 'food' current best two-tag sequence: JJ NN\n"
     ]
    }
   ],
   "source": [
    "for index in range(1,len_sample_sentence):\n",
    "    curr_viterbi={}\n",
    "    curr_backpointer={}\n",
    "    prev_viterbi=viterbi_main[-1]\n",
    "    \n",
    "    for brown_tag in distinct_brown_tags:\n",
    "        \n",
    "        if brown_tag != \"START\":\n",
    "            # if this tag is X and the current word is w, then\n",
    "            # find the previous tag Y such that\n",
    "            # the best tag sequence that ends in X\n",
    "            # actually ends in Y X\n",
    "            # that is, the Y that maximizes\n",
    "            # prev_viterbi[ Y ] * P(X | Y) * P( w | X)\n",
    "            # The following command has the same notation\n",
    "            # that you saw in the sorted() command.\n",
    "            prev_best = max(prev_viterbi.keys(),\n",
    "                                key=lambda prevtag: \\\n",
    "                                    prev_viterbi[prevtag] * cpd_tags[prevtag].prob(brown_tag) * cpd_tag_words[brown_tag].prob(\n",
    "                                        sample_sentences[index]))\n",
    "\n",
    "            curr_viterbi[brown_tag] = prev_viterbi[prev_best] * \\\n",
    "                                cpd_tags[prev_best].prob(brown_tag) * cpd_tag_words[brown_tag].prob(sample_sentences[index])\n",
    "            curr_backpointer[brown_tag] = prev_best\n",
    "\n",
    "    current_best = max(curr_viterbi.keys(), key=lambda tag: curr_viterbi[tag])\n",
    "    print(\"Word\", \"'\" + sample_sentences[index] + \"'\", \"current best two-tag sequence:\", curr_backpointer[current_best], current_best)\n",
    "\n",
    "\n",
    "    viterbi_main.append(curr_viterbi)\n",
    "    backpointer_main.append(curr_backpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "divided-study",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now find the probability of each tag\n",
    "# to have \"END\" as the next tag,\n",
    "# and use that to find the overall best sequence\n",
    "\n",
    "\n",
    "\n",
    "prev_viterbi = viterbi_main[-1]\n",
    "prev_best = max(prev_viterbi.keys(),\n",
    "                    key=lambda prev_tag: prev_viterbi[prev_tag] * cpd_tags[prev_tag].prob(\"END\"))\n",
    "\n",
    "prob_tag_sequence = prev_viterbi[prev_best] * cpd_tags[prev_best].prob(\"END\")\n",
    "\n",
    "\n",
    "best_tag_sequence = [\"END\", prev_best]\n",
    "# invert the list of backpointers\n",
    "backpointer_main.reverse()\n",
    "\n",
    "# go backwards through the list of backpointers\n",
    "# (or in this case forward, because we have inverter the backpointer list)\n",
    "# in each case:\n",
    "# the following best tag is the one listed under\n",
    "# the backpointer for the current best tag\n",
    "current_best_tag = prev_best\n",
    "for backpointer in backpointer_main:\n",
    "    best_tag_sequence.append(backpointer[current_best_tag])\n",
    "    current_best_tag = backpointer[current_best_tag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "congressional-royal",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_tag_sequence.reverse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "streaming-perception",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence given is :\n",
      "I \n",
      "love \n",
      "spicy \n",
      "food \n"
     ]
    }
   ],
   "source": [
    "print(\"The sentence given is :\")\n",
    "for word in sample_sentences:\n",
    "    print (word,\"\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "interpreted-pledge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best tag sequence using HMM for the given sentence is : \n",
      "START \n",
      "PP \n",
      "VB \n",
      "JJ \n",
      "NN \n",
      "END \n"
     ]
    }
   ],
   "source": [
    "print(\"The best tag sequence using HMM for the given sentence is : \")\n",
    "\n",
    "\n",
    "for best_tag in best_tag_sequence:\n",
    "    print (best_tag, \"\",)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
